"""Generates moda_preprocessed_segments.npz (~160 MB) and metadata.csv (~50 kB).

The file is a pre-processed (cropped and filtered) MODA dataset that includes only the
annotated portions.
Before running this script, run generate_moda_npz_files.py because it uses the files
generated by that script.

The generated file is the information source actually used to create a python
dataset of MODA to feed the models.
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import sys
from pprint import pprint

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.signal import butter, sosfiltfilt

project_root = os.path.abspath("..")
sys.path.append(project_root)

from sleeprnn.data import utils

# In this path we expect to find MODA metadata files and the npz files generated by
# generate_moda_npz_files.py script:
MODA_PATH = "../resources/datasets/moda"


def get_subjects():
    p1_info = pd.read_csv(
        os.path.join(MODA_PATH, "6_segListSrcDataLoc_p1.txt"), delimiter="\t"
    )
    p1_subjects = np.unique(p1_info.subjectID.values)
    p2_info = pd.read_csv(
        os.path.join(MODA_PATH, "7_segListSrcDataLoc_p2.txt"), delimiter="\t"
    )
    p2_subjects = np.unique(p2_info.subjectID.values)
    phase_dict = {}
    for subject_id in p1_subjects:
        phase_dict[subject_id] = 1
    for subject_id in p2_subjects:
        phase_dict[subject_id] = 2
    subject_ids = list(phase_dict.keys())
    subject_ids.sort()
    return subject_ids, phase_dict


def get_data(subject_id):
    data = np.load(os.path.join(MODA_PATH, "signals_npz/moda_%s.npz" % subject_id))
    fs = data["sampling_rate"].item()
    channel = data["channel"].item()
    signal = data["signal"]
    return signal, fs, channel


def get_annotations(subject_id):
    annot = pd.read_csv(
        os.path.join(MODA_PATH, "MODA_annotFiles/%s_MODA_GS.txt" % subject_id),
        delimiter="\t",
    )
    segments_info = annot[annot.eventName == "segmentViewed"]
    segments_start = np.sort(segments_info.startSec.values)
    spindles_info = annot[annot.eventName == "spindle"]
    spindles_start = spindles_info.startSec.values
    spindles_end = spindles_info.durationSec.values + spindles_start
    return segments_start, spindles_start, spindles_end


def get_segment(
    x,
    fs,
    start_time,
    segment_duration=115,
    border_duration=30,
    border_to_filter_duration=10,
):
    # Extract a single segment of EEG
    total_border = border_duration * fs + border_to_filter_duration * fs
    segment_size = 2 * total_border + segment_duration * fs
    start_sample = int(start_time * fs - total_border)
    end_sample = int(start_sample + segment_size)
    segment = x[start_sample:end_sample].copy()
    return segment


def filter_segment(
    x, fs, lowcut=0.3, highcut=30, filter_order=10, border_to_filter_duration=10
):
    sos = butter(filter_order, lowcut, btype="highpass", fs=fs, output="sos")
    x = sosfiltfilt(sos, x)
    sos = butter(filter_order, highcut, btype="lowpass", fs=fs, output="sos")
    x = sosfiltfilt(sos, x)
    border_size = int(fs * border_to_filter_duration)
    return x[border_size:-border_size]


def get_label(binaries, fs, start_time, segment_duration=115, border_duration=30):
    border_size = int(fs * border_duration)
    segment_size = 2 * border_size + segment_duration * fs
    start_sample = int(start_time * fs - border_size)
    end_sample = int(start_sample + segment_size)
    labels = binaries[start_sample:end_sample].copy()
    labels[:border_size] = -1
    labels[-border_size:] = -1

    return labels


if __name__ == "__main__":
    save_dir = "../resources/datasets/moda/segments"
    save_dir = os.path.abspath(save_dir)
    os.makedirs(save_dir, exist_ok=True)
    print("Files will be saved at %s" % save_dir)

    metadata_l = []
    segments_signal_l = []
    segments_labels_l = []
    segments_subjects_l = []
    segments_phases_l = []

    subject_ids, phase_dict = get_subjects()
    for subject_id in subject_ids:
        print(subject_id, flush=True)
        signal, fs, channel = get_data(subject_id)
        segments_start, spindles_start, spindles_end = get_annotations(subject_id)
        stamps_time = np.stack([spindles_start, spindles_end], axis=1)
        stamps = (stamps_time * fs).astype(np.int32)
        binary_labels = utils.stamp2seq(stamps, 0, signal.size - 1)
        for single_start in segments_start:
            segment_signal_prefilter = get_segment(signal, fs, single_start)
            segment_signal = filter_segment(segment_signal_prefilter, fs).astype(
                np.float32
            )
            segment_label = get_label(binary_labels, fs, single_start).astype(np.int8)
            # Append data
            segments_signal_l.append(segment_signal)
            segments_labels_l.append(segment_label)
            segments_subjects_l.append(subject_id)
            segments_phases_l.append(phase_dict[subject_id])
            metadata_l.append(
                {
                    "subject_id": subject_id,
                    "phase": phase_dict[subject_id],
                    "channel": channel,
                    "fs": fs,
                    "start_seconds": single_start,
                    "segment_seconds": 115,
                    "border_seconds": 30,
                }
            )

    # Format data
    segments_signal = np.stack(segments_signal_l, axis=0)
    segments_labels = np.stack(segments_labels_l, axis=0)
    segments_subjects = np.stack(segments_subjects_l, axis=0)
    segments_phases = np.stack(segments_phases_l, axis=0).astype(np.int8)
    metadata_table = pd.DataFrame(metadata_l)

    # Save data
    np.savez(
        os.path.join(save_dir, "moda_preprocessed_segments.npz"),
        signals=segments_signal,
        labels=segments_labels,
        subjects=segments_subjects,
        phases=segments_phases,
    )
    metadata_table.to_csv(os.path.join(save_dir, "metadata.csv"), sep="\t")
